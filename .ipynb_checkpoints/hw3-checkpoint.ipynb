{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "## I re-used my homework for Prof. Tran's AE598RL course last term. The original code is here: https://github.com/uiuc-ae598-rl-2023-spring/hw1-dp-LXYYY.git"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "4c1f36297f19619f"
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-04-04T06:27:17.369104Z",
     "start_time": "2024-04-04T06:27:17.323789Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.9892578125, 0.9453125, 0.828125, 0.623046875, 0.376953125, 0.171875, 0.0546875, 0.0107421875, 0.0009765625, 0, 0, 0], [0.998046875, 0.98046875, 0.91015625, 0.74609375, 0.5, 0.25390625, 0.08984375, 0.01953125, 0.001953125, 0, 0, 0], [1, 0.99609375, 0.96484375, 0.85546875, 0.63671875, 0.36328125, 0.14453125, 0.03515625, 0.00390625, 0, 0, 0], [0.0, 1, 0.9921875, 0.9375, 0.7734375, 0.5, 0.2265625, 0.0625, 0.0078125, 0, 0, 0], [0.0, 0.0, 1, 0.984375, 0.890625, 0.65625, 0.34375, 0.109375, 0.015625, 0, 0, 0], [0.0, 0.0, 0.0, 1, 0.96875, 0.8125, 0.5, 0.1875, 0.03125, 0, 0, 0], [0.0, 0.0, 0.0, 0.0, 1, 0.9375, 0.6875, 0.3125, 0.0625, 0, 0, 0], [0.0, 0.0, 0.0, 0.0, 0.0, 1, 0.875, 0.5, 0.125, 0, 0, 0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1, 0.75, 0.25, 0, 0, 0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1, 0.5, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0]]\n",
      "Optimal policy's win probability: 0.9892578125\n",
      "Policy sequence: ['B', 'B', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A']\n",
      "Simulated win probability: 0.25\n"
     ]
    }
   ],
   "source": [
    "def coin_game_DP():\n",
    "    # Initialize the DP table; +1 for extra head counts and +1 for 0-based indexing\n",
    "    dp = [[0 for _ in range(12)] for _ in\n",
    "          range(11)]  # 11 for the number of flips (0-10), 12 for heads (0-11, with 9+ as loss)\n",
    "    policy = [['' for _ in range(12)] for _ in range(11)]\n",
    "\n",
    "    # Base cases\n",
    "    dp[10][8] = 1  # Win condition if exactly 8 heads after 10 flips\n",
    "    for h in range(9, 12):  # Lose condition if more than 8 heads\n",
    "        dp[10][h] = 0\n",
    "\n",
    "    # DP table fill\n",
    "    for n in range(9, -1, -1):  # From 9 down to 0 flips\n",
    "        for h in range(8, -1, -1):  # Up to 8 heads, inclusive\n",
    "            # Coin A choice leads directly to the next state with one more head\n",
    "            probA = dp[n + 1][min(h + 1, 11)]  # min to cap heads at 11 (9+ considered as losing states)\n",
    "\n",
    "            # Coin B choice, with a fair chance of head or tail\n",
    "            probB = 0.5 * dp[n + 1][min(h + 1, 11)] + 0.5 * dp[n + 1][h]\n",
    "\n",
    "            # Select the action with the higher expected probability\n",
    "            if probA > probB:\n",
    "                dp[n][h] = probA\n",
    "                policy[n][h] = 'A'  # Choose coin A\n",
    "            else:\n",
    "                dp[n][h] = probB\n",
    "                policy[n][h] = 'B'  # Choose coin B\n",
    "\n",
    "    # Reconstruct the policy path\n",
    "    n, h = 0, 0\n",
    "    path = []\n",
    "    while n < 10:\n",
    "        decision = policy[n][h]\n",
    "        path.append(decision)\n",
    "        if decision == 'A':\n",
    "            h = min(h + 1, 11)  # Increment head count or cap\n",
    "        n += 1\n",
    "\n",
    "    print(dp)\n",
    "    return dp[0][0], path\n",
    "\n",
    "\n",
    "def simulate_policy(policy):\n",
    "    probability = 1.0  # Start with 100% probability\n",
    "    heads = 0  # Initial number of heads\n",
    "\n",
    "    # Simulate each decision in the policy\n",
    "    for n in range(10):  # For each flip\n",
    "        decision = policy[n]\n",
    "        if decision == 'A':\n",
    "            # Coin A (guaranteed head)\n",
    "            heads += 1\n",
    "            # Probability does not change as outcome is certain\n",
    "        elif decision == 'B':\n",
    "            # Coin B (fair coin, 50% head)\n",
    "            if heads < 8:\n",
    "                # Only if less than 8 heads, flipping coin B makes sense for trying to win\n",
    "                probability *= 0.5  # Update probability for the uncertain outcome\n",
    "\n",
    "        # If at any point heads exceed 8, the game is lost, so probability is 0\n",
    "        if heads > 8:\n",
    "            return 0.0\n",
    "\n",
    "    # If exactly 8 heads, return the accumulated probability, else 0\n",
    "    return probability\n",
    "\n",
    "\n",
    "probability, policy_path = coin_game_DP()\n",
    "print(f\"Optimal policy's win probability: {probability}\")\n",
    "print(f\"Policy sequence: {policy_path}\")\n",
    "print(f\"Simulated win probability: {simulate_policy(policy_path)}\")  # Should match the DP result\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-31T20:56:58.612155Z",
     "start_time": "2024-03-31T20:56:58.607338Z"
    }
   },
   "id": "cbeb9a79b4db532a",
   "execution_count": 8
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "delta: 5.434970448421403\n",
      "Learning finished after 0 epochs, converged False, delta 5.434970448421403\n",
      "delta: 4.709624691084699\n",
      "Learning finished after 1 epochs, converged False, delta 4.709624691084699\n",
      "delta: 4.471906384802198\n",
      "Learning finished after 2 epochs, converged False, delta 4.471906384802198\n",
      "delta: 4.246186910029309\n",
      "Learning finished after 3 epochs, converged False, delta 4.246186910029309\n",
      "delta: 4.03186062574558\n",
      "Learning finished after 4 epochs, converged False, delta 4.03186062574558\n",
      "delta: 3.828352460661069\n",
      "Learning finished after 5 epochs, converged False, delta 3.828352460661069\n",
      "delta: 3.6351163702092\n",
      "Learning finished after 6 epochs, converged False, delta 3.6351163702092\n",
      "delta: 3.4516338714228887\n",
      "Learning finished after 7 epochs, converged False, delta 3.4516338714228887\n",
      "delta: 3.2774126517628233\n",
      "Learning finished after 8 epochs, converged False, delta 3.2774126517628233\n",
      "delta: 3.111985248165091\n",
      "Learning finished after 9 epochs, converged False, delta 3.111985248165091\n",
      "delta: 2.9549077927639544\n",
      "Learning finished after 10 epochs, converged False, delta 2.9549077927639544\n",
      "delta: 2.8057588219242007\n",
      "Learning finished after 11 epochs, converged False, delta 2.8057588219242007\n",
      "delta: 2.664138145387575\n",
      "Learning finished after 12 epochs, converged False, delta 2.664138145387575\n",
      "delta: 2.529665772499129\n",
      "Learning finished after 13 epochs, converged False, delta 2.529665772499129\n",
      "delta: 2.4019808926322455\n",
      "Learning finished after 14 epochs, converged False, delta 2.4019808926322455\n",
      "delta: 2.280740907076627\n",
      "Learning finished after 15 epochs, converged False, delta 2.280740907076627\n",
      "delta: 2.1656205097919425\n",
      "Learning finished after 16 epochs, converged False, delta 2.1656205097919425\n",
      "delta: 2.0563108145601845\n",
      "Learning finished after 17 epochs, converged False, delta 2.0563108145601845\n",
      "delta: 1.952518526195263\n",
      "Learning finished after 18 epochs, converged False, delta 1.952518526195263\n",
      "delta: 1.8539651535855484\n",
      "Learning finished after 19 epochs, converged False, delta 1.8539651535855484\n",
      "delta: 1.7603862624583257\n",
      "Learning finished after 20 epochs, converged False, delta 1.7603862624583257\n",
      "delta: 1.6715307658607372\n",
      "Learning finished after 21 epochs, converged False, delta 1.6715307658607372\n",
      "delta: 1.587160250453934\n",
      "Learning finished after 22 epochs, converged False, delta 1.587160250453934\n",
      "delta: 1.507048336812261\n",
      "Learning finished after 23 epochs, converged False, delta 1.507048336812261\n",
      "delta: 1.430980072011664\n",
      "Learning finished after 24 epochs, converged False, delta 1.430980072011664\n",
      "delta: 1.3587513528768653\n",
      "Learning finished after 25 epochs, converged False, delta 1.3587513528768653\n",
      "delta: 1.290168378340411\n",
      "Learning finished after 26 epochs, converged False, delta 1.290168378340411\n",
      "delta: 1.2250471294436807\n",
      "Learning finished after 27 epochs, converged False, delta 1.2250471294436807\n",
      "delta: 1.1632128755850033\n",
      "Learning finished after 28 epochs, converged False, delta 1.1632128755850033\n",
      "delta: 1.1044997056898467\n",
      "Learning finished after 29 epochs, converged False, delta 1.1044997056898467\n",
      "delta: 1.0487500830451495\n",
      "Learning finished after 30 epochs, converged False, delta 1.0487500830451495\n",
      "delta: 0.9958144226034591\n",
      "Learning finished after 31 epochs, converged False, delta 0.9958144226034591\n",
      "delta: 0.9455506896225501\n",
      "Learning finished after 32 epochs, converged False, delta 0.9455506896225501\n",
      "delta: 0.8978240185638384\n",
      "Learning finished after 33 epochs, converged False, delta 0.8978240185638384\n",
      "delta: 0.852506351226836\n",
      "Learning finished after 34 epochs, converged False, delta 0.852506351226836\n",
      "delta: 0.8094760931486604\n",
      "Learning finished after 35 epochs, converged False, delta 0.8094760931486604\n",
      "delta: 0.7686177873469973\n",
      "Learning finished after 36 epochs, converged False, delta 0.7686177873469973\n",
      "delta: 0.7298218045306442\n",
      "Learning finished after 37 epochs, converged False, delta 0.7298218045306442\n",
      "delta: 0.6929840489469541\n",
      "Learning finished after 38 epochs, converged False, delta 0.6929840489469541\n",
      "delta: 0.6580056790763678\n",
      "Learning finished after 39 epochs, converged False, delta 0.6580056790763678\n",
      "delta: 0.6247928424249807\n",
      "Learning finished after 40 epochs, converged False, delta 0.6247928424249807\n",
      "delta: 0.5932564237035791\n",
      "Learning finished after 41 epochs, converged False, delta 0.5932564237035791\n",
      "delta: 0.5633118057171487\n",
      "Learning finished after 42 epochs, converged False, delta 0.5633118057171487\n",
      "delta: 0.5348786423235623\n",
      "Learning finished after 43 epochs, converged False, delta 0.5348786423235623\n",
      "delta: 0.5078806428522995\n",
      "Learning finished after 44 epochs, converged False, delta 0.5078806428522995\n",
      "delta: 0.48224536740431745\n",
      "Learning finished after 45 epochs, converged False, delta 0.48224536740431745\n",
      "delta: 0.4579040324845778\n",
      "Learning finished after 46 epochs, converged False, delta 0.4579040324845778\n",
      "delta: 0.43479132644493745\n",
      "Learning finished after 47 epochs, converged False, delta 0.43479132644493745\n",
      "delta: 0.4128452342426243\n",
      "Learning finished after 48 epochs, converged False, delta 0.4128452342426243\n",
      "delta: 0.3920068710442308\n",
      "Learning finished after 49 epochs, converged False, delta 0.3920068710442308\n",
      "delta: 0.372220324228266\n",
      "Learning finished after 50 epochs, converged False, delta 0.372220324228266\n",
      "delta: 0.35343250336285337\n",
      "Learning finished after 51 epochs, converged False, delta 0.35343250336285337\n",
      "delta: 0.3355929977556116\n",
      "Learning finished after 52 epochs, converged False, delta 0.3355929977556116\n",
      "delta: 0.3186539411938867\n",
      "Learning finished after 53 epochs, converged False, delta 0.3186539411938867\n",
      "delta: 0.30256988351212044\n",
      "Learning finished after 54 epochs, converged False, delta 0.30256988351212044\n",
      "delta: 0.28729766864185535\n",
      "Learning finished after 55 epochs, converged False, delta 0.28729766864185535\n",
      "delta: 0.27279631881715716\n",
      "Learning finished after 56 epochs, converged False, delta 0.27279631881715716\n",
      "delta: 0.25902692462486243\n",
      "Learning finished after 57 epochs, converged False, delta 0.25902692462486243\n",
      "delta: 0.24595254060442073\n",
      "Learning finished after 58 epochs, converged False, delta 0.24595254060442073\n",
      "delta: 0.2335380861174059\n",
      "Learning finished after 59 epochs, converged False, delta 0.2335380861174059\n",
      "delta: 0.22175025122064085\n",
      "Learning finished after 60 epochs, converged False, delta 0.22175025122064085\n",
      "delta: 0.21055740729026695\n",
      "Learning finished after 61 epochs, converged False, delta 0.21055740729026695\n",
      "delta: 0.19992952215729076\n",
      "Learning finished after 62 epochs, converged False, delta 0.19992952215729076\n",
      "delta: 0.1898380795264103\n",
      "Learning finished after 63 epochs, converged False, delta 0.1898380795264103\n",
      "delta: 0.18025600246231477\n",
      "Learning finished after 64 epochs, converged False, delta 0.18025600246231477\n",
      "delta: 0.17115758073802567\n",
      "Learning finished after 65 epochs, converged False, delta 0.17115758073802567\n",
      "delta: 0.1625184018502921\n",
      "Learning finished after 66 epochs, converged False, delta 0.1625184018502921\n",
      "delta: 0.154315285516887\n",
      "Learning finished after 67 epochs, converged False, delta 0.154315285516887\n",
      "delta: 0.14652622148041416\n",
      "Learning finished after 68 epochs, converged False, delta 0.14652622148041416\n",
      "delta: 0.1391303104511934\n",
      "Learning finished after 69 epochs, converged False, delta 0.1391303104511934\n",
      "delta: 0.1321077080311568\n",
      "Learning finished after 70 epochs, converged False, delta 0.1321077080311568\n",
      "delta: 0.12543957146829143\n",
      "Learning finished after 71 epochs, converged False, delta 0.12543957146829143\n",
      "delta: 0.11910800909842578\n",
      "Learning finished after 72 epochs, converged False, delta 0.11910800909842578\n",
      "delta: 0.11309603233920029\n",
      "Learning finished after 73 epochs, converged False, delta 0.11309603233920029\n",
      "delta: 0.10738751010687508\n",
      "Learning finished after 74 epochs, converged False, delta 0.10738751010687508\n",
      "delta: 0.10196712553423026\n",
      "Learning finished after 75 epochs, converged False, delta 0.10196712553423026\n",
      "delta: 0.09682033487288777\n",
      "Learning finished after 76 epochs, converged False, delta 0.09682033487288777\n",
      "delta: 0.09193332847017643\n",
      "Learning finished after 77 epochs, converged False, delta 0.09193332847017643\n",
      "delta: 0.08729299371564991\n",
      "Learning finished after 78 epochs, converged False, delta 0.08729299371564991\n",
      "delta: 0.08288687985785259\n",
      "Learning finished after 79 epochs, converged False, delta 0.08288687985785259\n",
      "delta: 0.0787031645970302\n",
      "Learning finished after 80 epochs, converged False, delta 0.0787031645970302\n",
      "delta: 0.07473062236398675\n",
      "Learning finished after 81 epochs, converged False, delta 0.07473062236398675\n",
      "delta: 0.07095859420016382\n",
      "Learning finished after 82 epochs, converged False, delta 0.07095859420016382\n",
      "delta: 0.06737695915789743\n",
      "Learning finished after 83 epochs, converged False, delta 0.06737695915789743\n",
      "delta: 0.06397610714441271\n",
      "Learning finished after 84 epochs, converged False, delta 0.06397610714441271\n",
      "delta: 0.060746913136298986\n",
      "Learning finished after 85 epochs, converged False, delta 0.060746913136298986\n",
      "delta: 0.05768071269575614\n",
      "Learning finished after 86 epochs, converged False, delta 0.05768071269575614\n",
      "delta: 0.05476927872243209\n",
      "Learning finished after 87 epochs, converged False, delta 0.05476927872243209\n",
      "delta: 0.05200479937890634\n",
      "Learning finished after 88 epochs, converged False, delta 0.05200479937890634\n",
      "delta: 0.04937985713026194\n",
      "Learning finished after 89 epochs, converged False, delta 0.04937985713026194\n",
      "delta: 0.04688740884162712\n",
      "Learning finished after 90 epochs, converged False, delta 0.04688740884162712\n",
      "delta: 0.044520766880324913\n",
      "Learning finished after 91 epochs, converged False, delta 0.044520766880324913\n",
      "delta: 0.04227358117204005\n",
      "Learning finished after 92 epochs, converged False, delta 0.04227358117204005\n",
      "delta: 0.04013982216238787\n",
      "Learning finished after 93 epochs, converged False, delta 0.04013982216238787\n",
      "delta: 0.03811376463875149\n",
      "Learning finished after 94 epochs, converged False, delta 0.03811376463875149\n",
      "delta: 0.03618997236858945\n",
      "Learning finished after 95 epochs, converged False, delta 0.03618997236858945\n",
      "delta: 0.03436328351330076\n",
      "Learning finished after 96 epochs, converged False, delta 0.03436328351330076\n",
      "delta: 0.03262879677797059\n",
      "Learning finished after 97 epochs, converged False, delta 0.03262879677797059\n",
      "delta: 0.030981858260588524\n",
      "Learning finished after 98 epochs, converged False, delta 0.030981858260588524\n",
      "delta: 0.029418048964899413\n",
      "Learning finished after 99 epochs, converged False, delta 0.029418048964899413\n",
      "delta: 0.027933172943392037\n",
      "Learning finished after 100 epochs, converged False, delta 0.027933172943392037\n",
      "delta: 0.026523246039076298\n",
      "Learning finished after 101 epochs, converged False, delta 0.026523246039076298\n",
      "delta: 0.02518448519523986\n",
      "Learning finished after 102 epochs, converged False, delta 0.02518448519523986\n",
      "delta: 0.023913298305032527\n",
      "Learning finished after 103 epochs, converged False, delta 0.023913298305032527\n",
      "delta: 0.02270627457308194\n",
      "Learning finished after 104 epochs, converged False, delta 0.02270627457308194\n",
      "delta: 0.021560175363987355\n",
      "Learning finished after 105 epochs, converged False, delta 0.021560175363987355\n",
      "delta: 0.02047192551249566\n",
      "Learning finished after 106 epochs, converged False, delta 0.02047192551249566\n",
      "delta: 0.019438605072267023\n",
      "Learning finished after 107 epochs, converged False, delta 0.019438605072267023\n",
      "delta: 0.01845744148124595\n",
      "Learning finished after 108 epochs, converged False, delta 0.01845744148124595\n",
      "delta: 0.017525802122463574\n",
      "Learning finished after 109 epochs, converged False, delta 0.017525802122463574\n",
      "delta: 0.016641187260333368\n",
      "Learning finished after 110 epochs, converged False, delta 0.016641187260333368\n",
      "delta: 0.015801223333355097\n",
      "Learning finished after 111 epochs, converged False, delta 0.015801223333355097\n",
      "delta: 0.01500365658560554\n",
      "Learning finished after 112 epochs, converged False, delta 0.01500365658560554\n",
      "delta: 0.014246347019451377\n",
      "Learning finished after 113 epochs, converged False, delta 0.014246347019451377\n",
      "delta: 0.013527262653653338\n",
      "Learning finished after 114 epochs, converged False, delta 0.013527262653653338\n",
      "delta: 0.012844474071201262\n",
      "Learning finished after 115 epochs, converged False, delta 0.012844474071201262\n",
      "delta: 0.012196149242470256\n",
      "Learning finished after 116 epochs, converged False, delta 0.012196149242470256\n",
      "delta: 0.011580548609444463\n",
      "Learning finished after 117 epochs, converged False, delta 0.011580548609444463\n",
      "delta: 0.010996020418389207\n",
      "Learning finished after 118 epochs, converged False, delta 0.010996020418389207\n",
      "delta: 0.010440996287769622\n",
      "Learning finished after 119 epochs, converged False, delta 0.010440996287769622\n",
      "delta: 0.009913987000146562\n",
      "Learning finished after 120 epochs, converged False, delta 0.009913987000146562\n",
      "delta: 0.009413578506311637\n",
      "Learning finished after 121 epochs, converged False, delta 0.009413578506311637\n",
      "delta: 0.00893842813121637\n",
      "Learning finished after 122 epochs, converged False, delta 0.00893842813121637\n",
      "delta: 0.008487260971293153\n",
      "Learning finished after 123 epochs, converged False, delta 0.008487260971293153\n",
      "delta: 0.008058866473760418\n",
      "Learning finished after 124 epochs, converged False, delta 0.008058866473760418\n",
      "delta: 0.007652095188490193\n",
      "Learning finished after 125 epochs, converged False, delta 0.007652095188490193\n",
      "delta: 0.007265855683854738\n",
      "Learning finished after 126 epochs, converged False, delta 0.007265855683854738\n",
      "delta: 0.0068991116182246515\n",
      "Learning finished after 127 epochs, converged False, delta 0.0068991116182246515\n",
      "delta: 0.006550878959288298\n",
      "Learning finished after 128 epochs, converged False, delta 0.006550878959288298\n",
      "delta: 0.006220223343817111\n",
      "Learning finished after 129 epochs, converged False, delta 0.006220223343817111\n",
      "delta: 0.00590625757052976\n",
      "Learning finished after 130 epochs, converged False, delta 0.00590625757052976\n",
      "delta: 0.005608139219674513\n",
      "Learning finished after 131 epochs, converged False, delta 0.005608139219674513\n",
      "delta: 0.005325068392551202\n",
      "Learning finished after 132 epochs, converged False, delta 0.005325068392551202\n",
      "delta: 0.005056285565444796\n",
      "Learning finished after 133 epochs, converged False, delta 0.005056285565444796\n",
      "delta: 0.004801069551518822\n",
      "Learning finished after 134 epochs, converged False, delta 0.004801069551518822\n",
      "delta: 0.004558735565922234\n",
      "Learning finished after 135 epochs, converged False, delta 0.004558735565922234\n",
      "delta: 0.004328633388212211\n",
      "Learning finished after 136 epochs, converged False, delta 0.004328633388212211\n",
      "delta: 0.004110145617957528\n",
      "Learning finished after 137 epochs, converged False, delta 0.004110145617957528\n",
      "delta: 0.0039026860178807965\n",
      "Learning finished after 138 epochs, converged False, delta 0.0039026860178807965\n",
      "delta: 0.003705697941143171\n",
      "Learning finished after 139 epochs, converged False, delta 0.003705697941143171\n",
      "delta: 0.0035186528375561466\n",
      "Learning finished after 140 epochs, converged False, delta 0.0035186528375561466\n",
      "delta: 0.0033410488355798407\n",
      "Learning finished after 141 epochs, converged False, delta 0.0033410488355798407\n",
      "delta: 0.0031724093956029265\n",
      "Learning finished after 142 epochs, converged False, delta 0.0031724093956029265\n",
      "delta: 0.003012282031363611\n",
      "Learning finished after 143 epochs, converged False, delta 0.003012282031363611\n",
      "delta: 0.002860237095816842\n",
      "Learning finished after 144 epochs, converged False, delta 0.002860237095816842\n",
      "delta: 0.0027158666284208266\n",
      "Learning finished after 145 epochs, converged False, delta 0.0027158666284208266\n",
      "delta: 0.002578783260346995\n",
      "Learning finished after 146 epochs, converged False, delta 0.002578783260346995\n",
      "delta: 0.002448619175268618\n",
      "Learning finished after 147 epochs, converged False, delta 0.002448619175268618\n",
      "delta: 0.002325025122402735\n",
      "Learning finished after 148 epochs, converged False, delta 0.002325025122402735\n",
      "delta: 0.0022076694793469187\n",
      "Learning finished after 149 epochs, converged False, delta 0.0022076694793469187\n",
      "delta: 0.0020962373623802932\n",
      "Learning finished after 150 epochs, converged False, delta 0.0020962373623802932\n",
      "delta: 0.0019904297815145355\n",
      "Learning finished after 151 epochs, converged False, delta 0.0019904297815145355\n",
      "delta: 0.001889962838291126\n",
      "Learning finished after 152 epochs, converged False, delta 0.001889962838291126\n",
      "delta: 0.0017945669640226924\n",
      "Learning finished after 153 epochs, converged False, delta 0.0017945669640226924\n",
      "delta: 0.0017039861965173486\n",
      "Learning finished after 154 epochs, converged False, delta 0.0017039861965173486\n",
      "delta: 0.0016179774932538749\n",
      "Learning finished after 155 epochs, converged False, delta 0.0016179774932538749\n",
      "delta: 0.001536310079274017\n",
      "Learning finished after 156 epochs, converged False, delta 0.001536310079274017\n",
      "delta: 0.0014587648280297572\n",
      "Learning finished after 157 epochs, converged False, delta 0.0014587648280297572\n",
      "delta: 0.001385133673323935\n",
      "Learning finished after 158 epochs, converged False, delta 0.001385133673323935\n",
      "delta: 0.0013152190511789286\n",
      "Learning finished after 159 epochs, converged False, delta 0.0013152190511789286\n",
      "delta: 0.0012488333695586107\n",
      "Learning finished after 160 epochs, converged False, delta 0.0012488333695586107\n",
      "delta: 0.0011857985052330378\n",
      "Learning finished after 161 epochs, converged False, delta 0.0011857985052330378\n",
      "delta: 0.0011259453256826646\n",
      "Learning finished after 162 epochs, converged False, delta 0.0011259453256826646\n",
      "delta: 0.001069113235374175\n",
      "Learning finished after 163 epochs, converged False, delta 0.001069113235374175\n",
      "delta: 0.0010151497448163127\n",
      "Learning finished after 164 epochs, converged False, delta 0.0010151497448163127\n",
      "delta: 0.0009639100614435847\n",
      "Learning finished after 165 epochs, converged False, delta 0.0009639100614435847\n",
      "delta: 0.0009152567010914936\n",
      "Learning finished after 166 epochs, converged False, delta 0.0009152567010914936\n",
      "delta: 0.0008690591190969599\n",
      "Learning finished after 167 epochs, converged False, delta 0.0008690591190969599\n",
      "delta: 0.0008251933600718075\n",
      "Learning finished after 168 epochs, converged False, delta 0.0008251933600718075\n",
      "delta: 0.0007835417252124444\n",
      "Learning finished after 169 epochs, converged False, delta 0.0007835417252124444\n",
      "delta: 0.0007439924566483569\n",
      "Learning finished after 170 epochs, converged False, delta 0.0007439924566483569\n",
      "delta: 0.0007064394373941241\n",
      "Learning finished after 171 epochs, converged False, delta 0.0007064394373941241\n",
      "delta: 0.0006707819067912624\n",
      "Learning finished after 172 epochs, converged False, delta 0.0006707819067912624\n",
      "delta: 0.0006369241900472389\n",
      "Learning finished after 173 epochs, converged False, delta 0.0006369241900472389\n",
      "delta: 0.0006047754415448026\n",
      "Learning finished after 174 epochs, converged False, delta 0.0006047754415448026\n",
      "delta: 0.0005742494011542476\n",
      "Learning finished after 175 epochs, converged False, delta 0.0005742494011542476\n",
      "delta: 0.0005452641626106924\n",
      "Learning finished after 176 epochs, converged False, delta 0.0005452641626106924\n",
      "delta: 0.0005177419540132178\n",
      "Learning finished after 177 epochs, converged False, delta 0.0005177419540132178\n",
      "delta: 0.0004916089288684589\n",
      "Learning finished after 178 epochs, converged False, delta 0.0004916089288684589\n",
      "delta: 0.0004667949681902428\n",
      "Learning finished after 179 epochs, converged False, delta 0.0004667949681902428\n",
      "delta: 0.00044323349217734176\n",
      "Learning finished after 180 epochs, converged False, delta 0.00044323349217734176\n",
      "delta: 0.0004208612816682944\n",
      "Learning finished after 181 epochs, converged False, delta 0.0004208612816682944\n",
      "delta: 0.00039961830846380053\n",
      "Learning finished after 182 epochs, converged False, delta 0.00039961830846380053\n",
      "delta: 0.00037944757434615894\n",
      "Learning finished after 183 epochs, converged False, delta 0.00037944757434615894\n",
      "delta: 0.0003602949580283621\n",
      "Learning finished after 184 epochs, converged False, delta 0.0003602949580283621\n",
      "delta: 0.00034210907003284774\n",
      "Learning finished after 185 epochs, converged False, delta 0.00034210907003284774\n",
      "delta: 0.0003248411147040997\n",
      "Learning finished after 186 epochs, converged False, delta 0.0003248411147040997\n",
      "delta: 0.00030844475944036276\n",
      "Learning finished after 187 epochs, converged False, delta 0.00030844475944036276\n",
      "delta: 0.00029287601022076615\n",
      "Learning finished after 188 epochs, converged False, delta 0.00029287601022076615\n",
      "delta: 0.0002780930935983861\n",
      "Learning finished after 189 epochs, converged False, delta 0.0002780930935983861\n",
      "delta: 0.0002640563447044997\n",
      "Learning finished after 190 epochs, converged False, delta 0.0002640563447044997\n",
      "delta: 0.00025072810069559637\n",
      "Learning finished after 191 epochs, converged False, delta 0.00025072810069559637\n",
      "delta: 0.00023807259982788764\n",
      "Learning finished after 192 epochs, converged False, delta 0.00023807259982788764\n",
      "delta: 0.00022605588534929666\n",
      "Learning finished after 193 epochs, converged False, delta 0.00022605588534929666\n",
      "delta: 0.0002146457145357772\n",
      "Learning finished after 194 epochs, converged False, delta 0.0002146457145357772\n",
      "delta: 0.000203811472090365\n",
      "Learning finished after 195 epochs, converged False, delta 0.000203811472090365\n",
      "delta: 0.00019352408803285925\n",
      "Learning finished after 196 epochs, converged False, delta 0.00019352408803285925\n",
      "delta: 0.0001837559596964411\n",
      "Learning finished after 197 epochs, converged False, delta 0.0001837559596964411\n",
      "delta: 0.00017448087763227704\n",
      "Learning finished after 198 epochs, converged False, delta 0.00017448087763227704\n",
      "delta: 0.00016567395532263163\n",
      "Learning finished after 199 epochs, converged False, delta 0.00016567395532263163\n",
      "delta: 0.0001573115624324828\n",
      "Learning finished after 200 epochs, converged False, delta 0.0001573115624324828\n",
      "delta: 0.000149371261315423\n",
      "Learning finished after 201 epochs, converged False, delta 0.000149371261315423\n",
      "delta: 0.00014183174690174383\n",
      "Learning finished after 202 epochs, converged False, delta 0.00014183174690174383\n",
      "delta: 0.000134672789471324\n",
      "Learning finished after 203 epochs, converged False, delta 0.000134672789471324\n",
      "delta: 0.00012787518042500778\n",
      "Learning finished after 204 epochs, converged False, delta 0.00012787518042500778\n",
      "delta: 0.00012142068069920242\n",
      "Learning finished after 205 epochs, converged False, delta 0.00012142068069920242\n",
      "delta: 0.0001152919718379053\n",
      "Learning finished after 206 epochs, converged False, delta 0.0001152919718379053\n",
      "delta: 0.0001094726095658416\n",
      "Learning finished after 207 epochs, converged False, delta 0.0001094726095658416\n",
      "delta: 0.00010394697959270616\n",
      "Learning finished after 208 epochs, converged False, delta 0.00010394697959270616\n",
      "delta: 9.870025579061803e-05\n",
      "Learning finished after 209 epochs, converged False, delta 9.870025579061803e-05\n",
      "delta: 9.371836038951642e-05\n",
      "Learning finished after 210 epochs, converged False, delta 9.371836038951642e-05\n",
      "delta: 8.898792614786544e-05\n",
      "Learning finished after 211 epochs, converged False, delta 8.898792614786544e-05\n",
      "delta: 8.449626058393278e-05\n",
      "Learning finished after 212 epochs, converged False, delta 8.449626058393278e-05\n",
      "delta: 8.023131182710586e-05\n",
      "Learning finished after 213 epochs, converged False, delta 8.023131182710586e-05\n",
      "delta: 7.618163635925157e-05\n",
      "Learning finished after 214 epochs, converged False, delta 7.618163635925157e-05\n",
      "delta: 7.233636826242673e-05\n",
      "Learning finished after 215 epochs, converged False, delta 7.233636826242673e-05\n",
      "delta: 6.868519007241503e-05\n",
      "Learning finished after 216 epochs, converged False, delta 6.868519007241503e-05\n",
      "delta: 6.521830511019289e-05\n",
      "Learning finished after 217 epochs, converged False, delta 6.521830511019289e-05\n",
      "delta: 6.192641116342656e-05\n",
      "Learning finished after 218 epochs, converged False, delta 6.192641116342656e-05\n",
      "delta: 5.8800675560632953e-05\n",
      "Learning finished after 219 epochs, converged False, delta 5.8800675560632953e-05\n",
      "delta: 5.583271145326307e-05\n",
      "Learning finished after 220 epochs, converged False, delta 5.583271145326307e-05\n",
      "delta: 5.3014555348340764e-05\n",
      "Learning finished after 221 epochs, converged False, delta 5.3014555348340764e-05\n",
      "delta: 5.0338645678493776e-05\n",
      "Learning finished after 222 epochs, converged False, delta 5.0338645678493776e-05\n",
      "delta: 4.779780252306409e-05\n",
      "Learning finished after 223 epochs, converged False, delta 4.779780252306409e-05\n",
      "delta: 4.538520845187577e-05\n",
      "Learning finished after 224 epochs, converged False, delta 4.538520845187577e-05\n",
      "delta: 4.3094390036912955e-05\n",
      "Learning finished after 225 epochs, converged False, delta 4.3094390036912955e-05\n",
      "delta: 4.091920069981825e-05\n",
      "Learning finished after 226 epochs, converged False, delta 4.091920069981825e-05\n",
      "delta: 3.8853804042560114e-05\n",
      "Learning finished after 227 epochs, converged False, delta 3.8853804042560114e-05\n",
      "delta: 3.6892658286546975e-05\n",
      "Learning finished after 228 epochs, converged False, delta 3.6892658286546975e-05\n",
      "delta: 3.5030501365440614e-05\n",
      "Learning finished after 229 epochs, converged False, delta 3.5030501365440614e-05\n",
      "delta: 3.326233681377744e-05\n",
      "Learning finished after 230 epochs, converged False, delta 3.326233681377744e-05\n",
      "delta: 3.158342035192163e-05\n",
      "Learning finished after 231 epochs, converged False, delta 3.158342035192163e-05\n",
      "delta: 2.998924720998275e-05\n",
      "Learning finished after 232 epochs, converged False, delta 2.998924720998275e-05\n",
      "delta: 2.847553996332408e-05\n",
      "Learning finished after 233 epochs, converged False, delta 2.847553996332408e-05\n",
      "delta: 2.7038237064402892e-05\n",
      "Learning finished after 234 epochs, converged False, delta 2.7038237064402892e-05\n",
      "delta: 2.56734820567317e-05\n",
      "Learning finished after 235 epochs, converged False, delta 2.56734820567317e-05\n",
      "delta: 2.4377613058845782e-05\n",
      "Learning finished after 236 epochs, converged False, delta 2.4377613058845782e-05\n",
      "delta: 2.314715304407855e-05\n",
      "Learning finished after 237 epochs, converged False, delta 2.314715304407855e-05\n",
      "delta: 2.1978800475608296e-05\n",
      "Learning finished after 238 epochs, converged False, delta 2.1978800475608296e-05\n",
      "delta: 2.0869420538360828e-05\n",
      "Learning finished after 239 epochs, converged False, delta 2.0869420538360828e-05\n",
      "delta: 1.9816036527231518e-05\n",
      "Learning finished after 240 epochs, converged False, delta 1.9816036527231518e-05\n",
      "delta: 1.8815822102169477e-05\n",
      "Learning finished after 241 epochs, converged False, delta 1.8815822102169477e-05\n",
      "delta: 1.7866093472207467e-05\n",
      "Learning finished after 242 epochs, converged False, delta 1.7866093472207467e-05\n",
      "delta: 1.6964302403721376e-05\n",
      "Learning finished after 243 epochs, converged False, delta 1.6964302403721376e-05\n",
      "delta: 1.6108029242900557e-05\n",
      "Learning finished after 244 epochs, converged False, delta 1.6108029242900557e-05\n",
      "delta: 1.5294976464019783e-05\n",
      "Learning finished after 245 epochs, converged False, delta 1.5294976464019783e-05\n",
      "delta: 1.4522962530350014e-05\n",
      "Learning finished after 246 epochs, converged False, delta 1.4522962530350014e-05\n",
      "delta: 1.378991599665369e-05\n",
      "Learning finished after 247 epochs, converged False, delta 1.378991599665369e-05\n",
      "delta: 1.3093869981162243e-05\n",
      "Learning finished after 248 epochs, converged False, delta 1.3093869981162243e-05\n",
      "delta: 1.2432956893349001e-05\n",
      "Learning finished after 249 epochs, converged False, delta 1.2432956893349001e-05\n",
      "delta: 1.1805403389075764e-05\n",
      "Learning finished after 250 epochs, converged False, delta 1.1805403389075764e-05\n",
      "delta: 1.1209525652589036e-05\n",
      "Learning finished after 251 epochs, converged False, delta 1.1209525652589036e-05\n",
      "delta: 1.064372484904652e-05\n",
      "Learning finished after 252 epochs, converged False, delta 1.064372484904652e-05\n",
      "delta: 1.0106482847049847e-05\n",
      "Learning finished after 253 epochs, converged False, delta 1.0106482847049847e-05\n",
      "delta: 9.596358111707559e-06\n",
      "Learning finished after 254 epochs, converged False, delta 9.596358111707559e-06\n",
      "delta: 9.111981938758618e-06\n",
      "Learning finished after 255 epochs, converged False, delta 9.111981938758618e-06\n",
      "delta: 8.652054646063334e-06\n",
      "Learning finished after 256 epochs, converged False, delta 8.652054646063334e-06\n",
      "delta: 8.215342177209095e-06\n",
      "Learning finished after 257 epochs, converged False, delta 8.215342177209095e-06\n",
      "delta: 7.800672804592068e-06\n",
      "Learning finished after 258 epochs, converged False, delta 7.800672804592068e-06\n",
      "delta: 7.406933832498908e-06\n",
      "Learning finished after 259 epochs, converged False, delta 7.406933832498908e-06\n",
      "delta: 7.033068854411795e-06\n",
      "Learning finished after 260 epochs, converged False, delta 7.033068854411795e-06\n",
      "delta: 6.678074711885529e-06\n",
      "Learning finished after 261 epochs, converged False, delta 6.678074711885529e-06\n",
      "delta: 6.340998879750259e-06\n",
      "Learning finished after 262 epochs, converged False, delta 6.340998879750259e-06\n",
      "delta: 6.020936965001056e-06\n",
      "Learning finished after 263 epochs, converged False, delta 6.020936965001056e-06\n",
      "delta: 5.7170301772657695e-06\n",
      "Learning finished after 264 epochs, converged False, delta 5.7170301772657695e-06\n",
      "delta: 5.4284630692791325e-06\n",
      "Learning finished after 265 epochs, converged False, delta 5.4284630692791325e-06\n",
      "delta: 5.154461405254551e-06\n",
      "Learning finished after 266 epochs, converged False, delta 5.154461405254551e-06\n",
      "delta: 4.894289958201625e-06\n",
      "Learning finished after 267 epochs, converged False, delta 4.894289958201625e-06\n",
      "delta: 4.647250676725889e-06\n",
      "Learning finished after 268 epochs, converged False, delta 4.647250676725889e-06\n",
      "delta: 4.412680709720007e-06\n",
      "Learning finished after 269 epochs, converged False, delta 4.412680709720007e-06\n",
      "delta: 4.189950644217788e-06\n",
      "Learning finished after 270 epochs, converged False, delta 4.189950644217788e-06\n",
      "delta: 3.978462871145894e-06\n",
      "Learning finished after 271 epochs, converged False, delta 3.978462871145894e-06\n",
      "delta: 3.7776499652864004e-06\n",
      "Learning finished after 272 epochs, converged False, delta 3.7776499652864004e-06\n",
      "delta: 3.5869730794502175e-06\n",
      "Learning finished after 273 epochs, converged False, delta 3.5869730794502175e-06\n",
      "delta: 3.405920608656743e-06\n",
      "Learning finished after 274 epochs, converged False, delta 3.405920608656743e-06\n",
      "delta: 3.234006769048392e-06\n",
      "Learning finished after 275 epochs, converged False, delta 3.234006769048392e-06\n",
      "delta: 3.0707702904919643e-06\n",
      "Learning finished after 276 epochs, converged False, delta 3.0707702904919643e-06\n",
      "delta: 2.915773151812573e-06\n",
      "Learning finished after 277 epochs, converged False, delta 2.915773151812573e-06\n",
      "delta: 2.768599500768687e-06\n",
      "Learning finished after 278 epochs, converged False, delta 2.768599500768687e-06\n",
      "delta: 2.6288544461294805e-06\n",
      "Learning finished after 279 epochs, converged False, delta 2.6288544461294805e-06\n",
      "delta: 2.4961630060715834e-06\n",
      "Learning finished after 280 epochs, converged False, delta 2.4961630060715834e-06\n",
      "delta: 2.370169184473525e-06\n",
      "Learning finished after 281 epochs, converged False, delta 2.370169184473525e-06\n",
      "delta: 2.2505348908907763e-06\n",
      "Learning finished after 282 epochs, converged False, delta 2.2505348908907763e-06\n",
      "delta: 2.1369391447478847e-06\n",
      "Learning finished after 283 epochs, converged False, delta 2.1369391447478847e-06\n",
      "delta: 2.0290771516329187e-06\n",
      "Learning finished after 284 epochs, converged False, delta 2.0290771516329187e-06\n",
      "delta: 1.926659464857039e-06\n",
      "Learning finished after 285 epochs, converged False, delta 1.926659464857039e-06\n",
      "delta: 1.8294113317551819e-06\n",
      "Learning finished after 286 epochs, converged False, delta 1.8294113317551819e-06\n",
      "delta: 1.7370717984022122e-06\n",
      "Learning finished after 287 epochs, converged False, delta 1.7370717984022122e-06\n",
      "delta: 1.649393112757025e-06\n",
      "Learning finished after 288 epochs, converged False, delta 1.649393112757025e-06\n",
      "delta: 1.5661399856981006e-06\n",
      "Learning finished after 289 epochs, converged False, delta 1.5661399856981006e-06\n",
      "delta: 1.4870890794327352e-06\n",
      "Learning finished after 290 epochs, converged False, delta 1.4870890794327352e-06\n",
      "delta: 1.4120282401108852e-06\n",
      "Learning finished after 291 epochs, converged False, delta 1.4120282401108852e-06\n",
      "delta: 1.3407561283429459e-06\n",
      "Learning finished after 292 epochs, converged False, delta 1.3407561283429459e-06\n",
      "delta: 1.2730814518135958e-06\n",
      "Learning finished after 293 epochs, converged False, delta 1.2730814518135958e-06\n",
      "delta: 1.2088226668538482e-06\n",
      "Learning finished after 294 epochs, converged False, delta 1.2088226668538482e-06\n",
      "delta: 1.1478073531634436e-06\n",
      "Learning finished after 295 epochs, converged False, delta 1.1478073531634436e-06\n",
      "delta: 1.0898717590634988e-06\n",
      "Learning finished after 296 epochs, converged False, delta 1.0898717590634988e-06\n",
      "delta: 1.0348604888577029e-06\n",
      "Learning finished after 297 epochs, converged False, delta 1.0348604888577029e-06\n",
      "delta: 9.826259059764197e-07\n",
      "Learning finished after 298 epochs, converged False, delta 9.826259059764197e-07\n",
      "delta: 9.330278771813028e-07\n",
      "Learning finished after 299 epochs, converged False, delta 9.330278771813028e-07\n",
      "delta: 8.859332893962346e-07\n",
      "Learning finished after 300 epochs, converged False, delta 8.859332893962346e-07\n",
      "delta: 8.412158081227972e-07\n",
      "Learning finished after 301 epochs, converged False, delta 8.412158081227972e-07\n",
      "delta: 7.987554226929205e-07\n",
      "Learning finished after 302 epochs, converged False, delta 7.987554226929205e-07\n",
      "delta: 7.584382473169171e-07\n",
      "Learning finished after 303 epochs, converged False, delta 7.584382473169171e-07\n",
      "delta: 7.201560805469853e-07\n",
      "Learning finished after 304 epochs, converged False, delta 7.201560805469853e-07\n",
      "delta: 6.838062063252437e-07\n",
      "Learning finished after 305 epochs, converged False, delta 6.838062063252437e-07\n",
      "delta: 6.492910813449271e-07\n",
      "Learning finished after 306 epochs, converged False, delta 6.492910813449271e-07\n",
      "delta: 6.165181218875659e-07\n",
      "Learning finished after 307 epochs, converged False, delta 6.165181218875659e-07\n",
      "delta: 5.853993769733279e-07\n",
      "Learning finished after 308 epochs, converged False, delta 5.853993769733279e-07\n",
      "delta: 5.558513436199064e-07\n",
      "Learning finished after 309 epochs, converged False, delta 5.558513436199064e-07\n",
      "delta: 5.277947394688454e-07\n",
      "Learning finished after 310 epochs, converged False, delta 5.277947394688454e-07\n",
      "delta: 5.011543038335731e-07\n",
      "Learning finished after 311 epochs, converged False, delta 5.011543038335731e-07\n",
      "delta: 4.7585854190401733e-07\n",
      "Learning finished after 312 epochs, converged False, delta 4.7585854190401733e-07\n",
      "delta: 4.5183958263805835e-07\n",
      "Learning finished after 313 epochs, converged False, delta 4.5183958263805835e-07\n",
      "delta: 4.290329798095627e-07\n",
      "Learning finished after 314 epochs, converged False, delta 4.290329798095627e-07\n",
      "delta: 4.0737754147812666e-07\n",
      "Learning finished after 315 epochs, converged False, delta 4.0737754147812666e-07\n",
      "delta: 3.8681515945881983e-07\n",
      "Learning finished after 316 epochs, converged False, delta 3.8681515945881983e-07\n",
      "delta: 3.672906672136378e-07\n",
      "Learning finished after 317 epochs, converged False, delta 3.672906672136378e-07\n",
      "delta: 3.4875166932124557e-07\n",
      "Learning finished after 318 epochs, converged False, delta 3.4875166932124557e-07\n",
      "delta: 3.3114842779014e-07\n",
      "Learning finished after 319 epochs, converged False, delta 3.3114842779014e-07\n",
      "delta: 3.1443370573924767e-07\n",
      "Learning finished after 320 epochs, converged False, delta 3.1443370573924767e-07\n",
      "delta: 2.985626679219422e-07\n",
      "Learning finished after 321 epochs, converged False, delta 2.985626679219422e-07\n",
      "delta: 2.8349271019578737e-07\n",
      "Learning finished after 322 epochs, converged False, delta 2.8349271019578737e-07\n",
      "delta: 2.6918341688997316e-07\n",
      "Learning finished after 323 epochs, converged False, delta 2.6918341688997316e-07\n",
      "delta: 2.555963760642044e-07\n",
      "Learning finished after 324 epochs, converged False, delta 2.555963760642044e-07\n",
      "delta: 2.4269516529784596e-07\n",
      "Learning finished after 325 epochs, converged False, delta 2.4269516529784596e-07\n",
      "delta: 2.3044511010539281e-07\n",
      "Learning finished after 326 epochs, converged False, delta 2.3044511010539281e-07\n",
      "delta: 2.1881339762330754e-07\n",
      "Learning finished after 327 epochs, converged False, delta 2.1881339762330754e-07\n",
      "delta: 2.0776880660378083e-07\n",
      "Learning finished after 328 epochs, converged False, delta 2.0776880660378083e-07\n",
      "delta: 1.9728167899302207e-07\n",
      "Learning finished after 329 epochs, converged False, delta 1.9728167899302207e-07\n",
      "delta: 1.8732386308784044e-07\n",
      "Learning finished after 330 epochs, converged False, delta 1.8732386308784044e-07\n",
      "delta: 1.7786869932479021e-07\n",
      "Learning finished after 331 epochs, converged False, delta 1.7786869932479021e-07\n",
      "delta: 1.6889077869564062e-07\n",
      "Learning finished after 332 epochs, converged False, delta 1.6889077869564062e-07\n",
      "delta: 1.603660280125041e-07\n",
      "Learning finished after 333 epochs, converged False, delta 1.603660280125041e-07\n",
      "delta: 1.5227155358843447e-07\n",
      "Learning finished after 334 epochs, converged False, delta 1.5227155358843447e-07\n",
      "delta: 1.445856412374269e-07\n",
      "Learning finished after 335 epochs, converged False, delta 1.445856412374269e-07\n",
      "delta: 1.3728767100928962e-07\n",
      "Learning finished after 336 epochs, converged False, delta 1.3728767100928962e-07\n",
      "delta: 1.303580603462251e-07\n",
      "Learning finished after 337 epochs, converged False, delta 1.303580603462251e-07\n",
      "delta: 1.2377826408283e-07\n",
      "Learning finished after 338 epochs, converged False, delta 1.2377826408283e-07\n",
      "delta: 1.1753054707241972e-07\n",
      "Learning finished after 339 epochs, converged False, delta 1.1753054707241972e-07\n",
      "delta: 1.1159819734984922e-07\n",
      "Learning finished after 340 epochs, converged False, delta 1.1159819734984922e-07\n",
      "delta: 1.0596527033612801e-07\n",
      "Learning finished after 341 epochs, converged False, delta 1.0596527033612801e-07\n",
      "delta: 1.0061667410354858e-07\n",
      "Learning finished after 342 epochs, converged False, delta 1.0061667410354858e-07\n",
      "delta: 9.553805568884854e-08\n",
      "Learning finished after 343 epochs, converged False, delta 9.553805568884854e-08\n",
      "delta: 9.071575846064661e-08\n",
      "Learning finished after 344 epochs, converged False, delta 9.071575846064661e-08\n",
      "delta: 8.613689317371609e-08\n",
      "Learning finished after 345 epochs, converged False, delta 8.613689317371609e-08\n",
      "delta: 8.178912480616418e-08\n",
      "Learning finished after 346 epochs, converged False, delta 8.178912480616418e-08\n",
      "delta: 7.766081466797914e-08\n",
      "Learning finished after 347 epochs, converged False, delta 7.766081466797914e-08\n",
      "delta: 7.374090671419253e-08\n",
      "Learning finished after 348 epochs, converged False, delta 7.374090671419253e-08\n",
      "delta: 7.001882806889625e-08\n",
      "Learning finished after 349 epochs, converged False, delta 7.001882806889625e-08\n",
      "delta: 6.648461692293495e-08\n",
      "Learning finished after 350 epochs, converged False, delta 6.648461692293495e-08\n",
      "delta: 6.312880884706829e-08\n",
      "Learning finished after 351 epochs, converged False, delta 6.312880884706829e-08\n",
      "delta: 5.994237994855212e-08\n",
      "Learning finished after 352 epochs, converged False, delta 5.994237994855212e-08\n",
      "delta: 5.69167895037026e-08\n",
      "Learning finished after 353 epochs, converged False, delta 5.69167895037026e-08\n",
      "delta: 5.404390890362265e-08\n",
      "Learning finished after 354 epochs, converged False, delta 5.404390890362265e-08\n",
      "delta: 5.131606428676605e-08\n",
      "Learning finished after 355 epochs, converged False, delta 5.131606428676605e-08\n",
      "delta: 4.8725866008680896e-08\n",
      "Learning finished after 356 epochs, converged False, delta 4.8725866008680896e-08\n",
      "delta: 4.6266421804830316e-08\n",
      "Learning finished after 357 epochs, converged False, delta 4.6266421804830316e-08\n",
      "delta: 4.3931137838626455e-08\n",
      "Learning finished after 358 epochs, converged False, delta 4.3931137838626455e-08\n",
      "delta: 4.1713704490575765e-08\n",
      "Learning finished after 359 epochs, converged False, delta 4.1713704490575765e-08\n",
      "delta: 3.960821004511672e-08\n",
      "Learning finished after 360 epochs, converged False, delta 3.960821004511672e-08\n",
      "delta: 3.760898437121796e-08\n",
      "Learning finished after 361 epochs, converged False, delta 3.760898437121796e-08\n",
      "delta: 3.571066997665184e-08\n",
      "Learning finished after 362 epochs, converged False, delta 3.571066997665184e-08\n",
      "delta: 3.3908179375430336e-08\n",
      "Learning finished after 363 epochs, converged False, delta 3.3908179375430336e-08\n",
      "delta: 3.219666666609555e-08\n",
      "Learning finished after 364 epochs, converged False, delta 3.219666666609555e-08\n",
      "delta: 3.057154174257448e-08\n",
      "Learning finished after 365 epochs, converged False, delta 3.057154174257448e-08\n",
      "delta: 2.9028441872469557e-08\n",
      "Learning finished after 366 epochs, converged False, delta 2.9028441872469557e-08\n",
      "delta: 2.7563231697058654e-08\n",
      "Learning finished after 367 epochs, converged False, delta 2.7563231697058654e-08\n",
      "delta: 2.6171974809585663e-08\n",
      "Learning finished after 368 epochs, converged False, delta 2.6171974809585663e-08\n",
      "delta: 2.4850933755260485e-08\n",
      "Learning finished after 369 epochs, converged False, delta 2.4850933755260485e-08\n",
      "delta: 2.3596598452968465e-08\n",
      "Learning finished after 370 epochs, converged False, delta 2.3596598452968465e-08\n",
      "delta: 2.240554408672324e-08\n",
      "Learning finished after 371 epochs, converged False, delta 2.240554408672324e-08\n",
      "delta: 2.1274644268487464e-08\n",
      "Learning finished after 372 epochs, converged False, delta 2.1274644268487464e-08\n",
      "delta: 2.0200801031933224e-08\n",
      "Learning finished after 373 epochs, converged False, delta 2.0200801031933224e-08\n",
      "delta: 1.9181157995262765e-08\n",
      "Learning finished after 374 epochs, converged False, delta 1.9181157995262765e-08\n",
      "delta: 1.8212986674370768e-08\n",
      "Learning finished after 375 epochs, converged False, delta 1.8212986674370768e-08\n",
      "delta: 1.729368648284435e-08\n",
      "Learning finished after 376 epochs, converged False, delta 1.729368648284435e-08\n",
      "delta: 1.6420798942817783e-08\n",
      "Learning finished after 377 epochs, converged False, delta 1.6420798942817783e-08\n",
      "delta: 1.5591950841553626e-08\n",
      "Learning finished after 378 epochs, converged False, delta 1.5591950841553626e-08\n",
      "delta: 1.4804939496571023e-08\n",
      "Learning finished after 379 epochs, converged False, delta 1.4804939496571023e-08\n",
      "delta: 1.4057675912226841e-08\n",
      "Learning finished after 380 epochs, converged False, delta 1.4057675912226841e-08\n",
      "delta: 1.3348099514587375e-08\n",
      "Learning finished after 381 epochs, converged False, delta 1.3348099514587375e-08\n",
      "delta: 1.2674362892539648e-08\n",
      "Learning finished after 382 epochs, converged False, delta 1.2674362892539648e-08\n",
      "delta: 1.20346328458254e-08\n",
      "Learning finished after 383 epochs, converged False, delta 1.20346328458254e-08\n",
      "delta: 1.142718986102409e-08\n",
      "Learning finished after 384 epochs, converged False, delta 1.142718986102409e-08\n",
      "delta: 1.085039968984347e-08\n",
      "Learning finished after 385 epochs, converged False, delta 1.085039968984347e-08\n",
      "delta: 1.0302713349119585e-08\n",
      "Learning finished after 386 epochs, converged False, delta 1.0302713349119585e-08\n",
      "delta: 9.782695542526199e-09\n",
      "Learning finished after 387 epochs, converged False, delta 9.782695542526199e-09\n",
      "delta: 9.28889676288236e-09\n",
      "Learning finished after 388 epochs, converged False, delta 9.28889676288236e-09\n",
      "delta: 8.820052244118415e-09\n",
      "Learning finished after 389 epochs, converged False, delta 8.820052244118415e-09\n",
      "delta: 8.374854587600566e-09\n",
      "Learning finished after 390 epochs, converged False, delta 8.374854587600566e-09\n",
      "delta: 7.952152714096883e-09\n",
      "Learning finished after 391 epochs, converged False, delta 7.952152714096883e-09\n",
      "delta: 7.550752911811287e-09\n",
      "Learning finished after 392 epochs, converged False, delta 7.550752911811287e-09\n",
      "delta: 7.1696319992042845e-09\n",
      "Learning finished after 393 epochs, converged False, delta 7.1696319992042845e-09\n",
      "delta: 6.80773837302695e-09\n",
      "Learning finished after 394 epochs, converged False, delta 6.80773837302695e-09\n",
      "delta: 6.464119906013366e-09\n",
      "Learning finished after 395 epochs, converged False, delta 6.464119906013366e-09\n",
      "delta: 6.137838681752328e-09\n",
      "Learning finished after 396 epochs, converged False, delta 6.137838681752328e-09\n",
      "delta: 5.828027838106209e-09\n",
      "Learning finished after 397 epochs, converged False, delta 5.828027838106209e-09\n",
      "delta: 5.533848934646812e-09\n",
      "Learning finished after 398 epochs, converged False, delta 5.533848934646812e-09\n",
      "delta: 5.254548796074232e-09\n",
      "Learning finished after 399 epochs, converged False, delta 5.254548796074232e-09\n",
      "delta: 4.989317403669702e-09\n",
      "Learning finished after 400 epochs, converged False, delta 4.989317403669702e-09\n",
      "delta: 4.737472636406892e-09\n",
      "Learning finished after 401 epochs, converged False, delta 4.737472636406892e-09\n",
      "delta: 4.498360794968903e-09\n",
      "Learning finished after 402 epochs, converged False, delta 4.498360794968903e-09\n",
      "delta: 4.271313969184121e-09\n",
      "Learning finished after 403 epochs, converged False, delta 4.271313969184121e-09\n",
      "delta: 4.055706881445076e-09\n",
      "Learning finished after 404 epochs, converged False, delta 4.055706881445076e-09\n",
      "delta: 3.850999519272591e-09\n",
      "Learning finished after 405 epochs, converged False, delta 3.850999519272591e-09\n",
      "delta: 3.656623448478058e-09\n",
      "Learning finished after 406 epochs, converged False, delta 3.656623448478058e-09\n",
      "delta: 3.472038656582299e-09\n",
      "Learning finished after 407 epochs, converged False, delta 3.472038656582299e-09\n",
      "delta: 3.296790396234428e-09\n",
      "Learning finished after 408 epochs, converged False, delta 3.296790396234428e-09\n",
      "delta: 3.1303954983741278e-09\n",
      "Learning finished after 409 epochs, converged False, delta 3.1303954983741278e-09\n",
      "delta: 2.972399215650512e-09\n",
      "Learning finished after 410 epochs, converged False, delta 2.972399215650512e-09\n",
      "delta: 2.822361011567409e-09\n",
      "Learning finished after 411 epochs, converged False, delta 2.822361011567409e-09\n",
      "delta: 2.679897193047509e-09\n",
      "Learning finished after 412 epochs, converged False, delta 2.679897193047509e-09\n",
      "delta: 2.544624067013501e-09\n",
      "Learning finished after 413 epochs, converged False, delta 2.544624067013501e-09\n",
      "delta: 2.4161863620975055e-09\n",
      "Learning finished after 414 epochs, converged False, delta 2.4161863620975055e-09\n",
      "delta: 2.294243017786357e-09\n",
      "Learning finished after 415 epochs, converged False, delta 2.294243017786357e-09\n",
      "delta: 2.178438762712176e-09\n",
      "Learning finished after 416 epochs, converged False, delta 2.178438762712176e-09\n",
      "delta: 2.068475168925943e-09\n",
      "Learning finished after 417 epochs, converged False, delta 2.068475168925943e-09\n",
      "delta: 1.9640680193333537e-09\n",
      "Learning finished after 418 epochs, converged False, delta 1.9640680193333537e-09\n",
      "delta: 1.8649330968401046e-09\n",
      "Learning finished after 419 epochs, converged False, delta 1.8649330968401046e-09\n",
      "delta: 1.7707861843518913e-09\n",
      "Learning finished after 420 epochs, converged False, delta 1.7707861843518913e-09\n",
      "delta: 1.681428329902701e-09\n",
      "Learning finished after 421 epochs, converged False, delta 1.681428329902701e-09\n",
      "delta: 1.5965611055435147e-09\n",
      "Learning finished after 422 epochs, converged False, delta 1.5965611055435147e-09\n",
      "delta: 1.515957137598889e-09\n",
      "Learning finished after 423 epochs, converged False, delta 1.515957137598889e-09\n",
      "delta: 1.4394316849575262e-09\n",
      "Learning finished after 424 epochs, converged False, delta 1.4394316849575262e-09\n",
      "delta: 1.3668000065081287e-09\n",
      "Learning finished after 425 epochs, converged False, delta 1.3668000065081287e-09\n",
      "delta: 1.297806306865823e-09\n",
      "Learning finished after 426 epochs, converged False, delta 1.297806306865823e-09\n",
      "delta: 1.2322942666287418e-09\n",
      "Learning finished after 427 epochs, converged False, delta 1.2322942666287418e-09\n",
      "delta: 1.1700933555403026e-09\n",
      "Learning finished after 428 epochs, converged False, delta 1.1700933555403026e-09\n",
      "delta: 1.111033043343923e-09\n",
      "Learning finished after 429 epochs, converged False, delta 1.111033043343923e-09\n",
      "delta: 1.054957010637736e-09\n",
      "Learning finished after 430 epochs, converged False, delta 1.054957010637736e-09\n",
      "delta: 1.0016947271651588e-09\n",
      "Learning finished after 431 epochs, converged False, delta 1.0016947271651588e-09\n",
      "delta: 9.511467169431853e-10\n",
      "Learning finished after 432 epochs, converged True, delta 9.511467169431853e-10\n"
     ]
    }
   ],
   "source": [
    "from good_bad import GoodBad\n",
    "\n",
    "env = GoodBad()\n",
    "\n",
    "# from models.policy_iteration.policy_iteration import learn\n",
    "from models.value_iteration.value_iteration import learn\n",
    "\n",
    "# from models.q_learning.q_learning import learn\n",
    "model = learn(env, scene=\"good_bad\", max_it=1000, gamma=0.9, epsilon=1e-3, alpha=0.1)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-31T21:05:45.701016Z",
     "start_time": "2024-03-31T21:05:45.592536Z"
    }
   },
   "id": "8684eacac2784229",
   "execution_count": 1
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total reward with policy (1): -1000000\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[10], line 46\u001B[0m\n\u001B[1;32m     44\u001B[0m a \u001B[38;5;241m=\u001B[39m get_action_from_belief(model, b, s, random\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m)\n\u001B[1;32m     45\u001B[0m b \u001B[38;5;241m=\u001B[39m model\u001B[38;5;241m.\u001B[39mupdate_belief(s, b, a)\n\u001B[0;32m---> 46\u001B[0m s1, r, done \u001B[38;5;241m=\u001B[39m \u001B[43menv\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mstep\u001B[49m\u001B[43m(\u001B[49m\u001B[43ma\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     47\u001B[0m r_sum \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m r\n\u001B[1;32m     48\u001B[0m s \u001B[38;5;241m=\u001B[39m s1\n",
      "File \u001B[0;32m~/workspaces/aao_hw/good_bad.py:52\u001B[0m, in \u001B[0;36mGoodBad.step\u001B[0;34m(self, a)\u001B[0m\n\u001B[1;32m     49\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m1\u001B[39m\n\u001B[1;32m     50\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;241m0\u001B[39m\n\u001B[0;32m---> 52\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mstep\u001B[39m(\u001B[38;5;28mself\u001B[39m, a):\n\u001B[1;32m     53\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mlast_action \u001B[38;5;241m=\u001B[39m a\n\u001B[1;32m     55\u001B[0m     r \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mr(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39ms, a)\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "s = env.reset()\n",
    "\n",
    "max_sim_steps = 1000000\n",
    "\n",
    "from models.base_model import ModelBasedAlg\n",
    "\n",
    "\n",
    "def get_action_from_belief(model: ModelBasedAlg, b, s, random):\n",
    "    v0 = model.get_values(0)\n",
    "    v1 = model.get_values(1)\n",
    "    if random:\n",
    "        model_policy_0 = model.get_policy(0)\n",
    "        model_policy_1 = model.get_policy(1)\n",
    "        return np.random.choice([model_policy_0, model_policy_1], p=b)\n",
    "    else:\n",
    "        # try all action\n",
    "        max_value = -np.inf\n",
    "        best_action = None\n",
    "        for a in [0, 1, 2]:\n",
    "            new_b = model.update_belief(s, b, a)\n",
    "            new_value = new_b[0] * v0 + new_b[1] * v1\n",
    "            if new_value > max_value:\n",
    "                max_value = new_value\n",
    "                best_action = a\n",
    "        return best_action\n",
    "\n",
    "\n",
    "r_sum = 0\n",
    "b = np.asarray([1, 0])\n",
    "for i in range(max_sim_steps):\n",
    "    a = get_action_from_belief(model, b, s, random=False)\n",
    "    b = model.update_belief(s, b, a)\n",
    "    s1, r, done = env.step(a)\n",
    "    r_sum += r\n",
    "    s = s1\n",
    "    if done:\n",
    "        break\n",
    "print(f\"Total reward with policy (1): {r_sum}\")\n",
    "\n",
    "s = env.reset()\n",
    "r_sum = 0\n",
    "b = np.asarray([1, 0])\n",
    "for i in range(max_sim_steps):\n",
    "    a = get_action_from_belief(model, b, s, random=True)\n",
    "    b = model.update_belief(s, b, a)\n",
    "    s1, r, done = env.step(a)\n",
    "    r_sum += r\n",
    "    s = s1\n",
    "    if done:\n",
    "        break\n",
    "print(f\"Total reward with policy (2): {r_sum}\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-31T20:57:01.508130Z",
     "start_time": "2024-03-31T20:56:58.628393Z"
    }
   },
   "id": "eb5fdde6f269c1d4",
   "execution_count": 10
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 0 of 1000 finished\n",
      "Episode 100 of 1000 finished\n",
      "Episode 200 of 1000 finished\n",
      "Episode 300 of 1000 finished\n",
      "Episode 400 of 1000 finished\n",
      "Episode 500 of 1000 finished\n",
      "Episode 600 of 1000 finished\n",
      "Episode 700 of 1000 finished\n",
      "Episode 800 of 1000 finished\n",
      "Episode 900 of 1000 finished\n",
      "[[74.55007247 87.3952746  80.92021661]\n",
      " [73.03538937 69.23336605 71.97633751]]\n",
      "[1 0]\n"
     ]
    }
   ],
   "source": [
    "from models.q_learning.q_learning import learn as q_learn\n",
    "from good_bad import GoodBad\n",
    "\n",
    "env = GoodBad(100)\n",
    "model = q_learn(env, scene=\"good_bad\", max_it=1000, gamma=0.9, epsilon=0.3, alpha=0.1)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-31T21:07:40.517768Z",
     "start_time": "2024-03-31T21:07:40.090959Z"
    }
   },
   "id": "c63da4d27a678ed4",
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'env' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[1], line 1\u001B[0m\n\u001B[0;32m----> 1\u001B[0m s \u001B[38;5;241m=\u001B[39m \u001B[43menv\u001B[49m\u001B[38;5;241m.\u001B[39mreset()\n\u001B[1;32m      2\u001B[0m r_sum \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m0\u001B[39m\n\u001B[1;32m      3\u001B[0m b \u001B[38;5;241m=\u001B[39m np\u001B[38;5;241m.\u001B[39masarray([\u001B[38;5;241m1\u001B[39m, \u001B[38;5;241m0\u001B[39m])\n",
      "\u001B[0;31mNameError\u001B[0m: name 'env' is not defined"
     ]
    }
   ],
   "source": [
    "s = env.reset()\n",
    "r_sum = 0\n",
    "b = np.asarray([1, 0])\n",
    "for i in range(max_sim_steps):\n",
    "    a = model.get_policy(s)\n",
    "    s1, r, done = env.step(a)\n",
    "    r_sum += r\n",
    "    s = s1\n",
    "    if done:\n",
    "        break\n",
    "print(f\"Total reward with policy (1): {r_sum}\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-03T14:12:10.018172Z",
     "start_time": "2024-04-03T14:12:09.947172Z"
    }
   },
   "id": "18fa20f975fb9aed",
   "execution_count": 1
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 0 of 100000 finished\n",
      "Episode 10000 of 100000 finished\n",
      "Episode 20000 of 100000 finished\n",
      "Episode 30000 of 100000 finished\n",
      "Episode 40000 of 100000 finished\n",
      "Episode 50000 of 100000 finished\n",
      "Episode 60000 of 100000 finished\n",
      "Episode 70000 of 100000 finished\n",
      "Episode 80000 of 100000 finished\n",
      "Episode 90000 of 100000 finished\n",
      "[[ 2.88625420e-01  8.09418006e-01  6.74802348e-01  8.66012832e-01]\n",
      " [ 7.00683109e-01  2.28076797e-01  3.82835118e-01  6.92589967e-01]\n",
      " [ 7.56250717e-01  4.22848348e-01  5.00436106e-01  8.75481984e-01]\n",
      " ...\n",
      " [ 3.12890252e-01  5.88496802e-01  6.49462707e-01  7.54496301e-02]\n",
      " [ 3.04901714e+00  1.28318460e+02  1.38134443e+02 -9.98051814e-01]\n",
      " [-1.33751822e-01  1.23550646e+02  4.43318929e+01  5.93982330e+01]]\n",
      "(490, 4)\n",
      "[3 0 3 0 0 2 3 3 1 3 2 1 1 0 3 2 3 3 3 3 3 3 1 3 3 0 3 3 3 3 2 2 2 1 3 3 2\n",
      " 1 3 2 0 1 0 0 3 3 3 2 1 0 3 3 0 3 3 0 1 1 3 1 3 3 0 0 3 1 2 2 2 3 0 1 2 1\n",
      " 3 0 0 0 2 3 3 1 1 1 0 3 2 3 2 3 3 2 2 3 1 1 3 3 3 0 3 1 1 1 1 0 3 1 3 3 0\n",
      " 3 3 0 2 1 3 3 3 1 3 3 0 1 3 3 2 0 2 3 1 2 1 3 0 3 3 3 3 2 3 3 2 2 3 2 3 1\n",
      " 3 3 2 0 3 0 3 0 3 3 3 2 1 0 3 1 3 3 2 3 3 3 1 0 0 1 3 0 3 3 0 3 1 3 1 0 3\n",
      " 3 0 2 3 3 3 1 0 0 1 2 3 3 1 1 1 0 0 3 1 3 3 2 3 3 3 3 3 1 0 1 0 1 1 1 2 3\n",
      " 0 1 3 2 3 3 3 0 0 1 2 1 3 1 0 2 2 1 0 0 1 0 3 0 1 1 1 2 2 0 0 2 3 2 2 2 3\n",
      " 2 2 1 1 1 0 2 2 2 1 0 0 1 1 3 1 2 3 2 0 2 0 3 3 2 3 0 3 0 1 2 3 3 1 2 3 0\n",
      " 3 3 0 1 0 0 0 0 3 0 3 2 2 2 1 0 3 2 2 1 2 2 0 2 3 1 2 1 0 0 2 2 2 2 3 2 2\n",
      " 3 0 2 2 2 1 3 3 0 1 0 1 2 2 2 1 1 1 0 2 0 3 0 2 3 0 0 2 1 0 1 1 0 0 3 0 0\n",
      " 1 1 0 1 0 0 2 2 0 3 3 1 1 3 2 3 3 2 2 3 0 1 2 2 1 2 3 2 2 3 2 2 1 2 2 0 2\n",
      " 2 2 1 3 1 1 3 0 2 0 2 1 1 1 3 3 0 2 0 0 2 0 3 3 1 0 2 2 0 0 3 0 1 2 1 1 1\n",
      " 3 0 2 2 3 0 2 1 2 0 1 1 2 2 2 3 3 3 3 2 3 0 2 2 2 2 3 3 3 1 2 1 0 1 2 2 3\n",
      " 0 2 1 3 0 3 2 2 1]\n",
      "[[0.28862542 0.80941801 0.67480235 0.86601283]\n",
      " [0.06088332 0.75586307 0.83691995 0.08209018]\n",
      " [0.95429531 0.02521111 0.51523693 0.97225161]\n",
      " [0.73354148 0.04241601 0.82622164 0.30587862]\n",
      " [0.88369485 0.69476795 0.5990135  0.71616251]\n",
      " [0.33269498 0.5826017  0.71619379 0.9958472 ]\n",
      " [0.17919563 0.41586433 0.64794639 0.92968711]\n",
      " [0.98562996 0.53087325 0.91315943 0.05994914]\n",
      " [0.16707427 0.37093861 0.29183721 0.84910185]\n",
      " [0.57523321 0.01826623 0.2255128  0.81526108]\n",
      " [0.3445927  0.24834839 0.37201278 0.75460908]\n",
      " [0.59908784 0.2912232  0.21155836 0.18622601]\n",
      " [0.47089336 0.53979517 0.15075302 0.77572384]\n",
      " [0.14675873 0.961996   0.91290283 0.29226254]\n",
      " [0.8691492  0.30776433 0.87463573 0.9770916 ]\n",
      " [0.02193894 0.10616036 0.46308395 0.20405355]\n",
      " [0.76958935 0.97916321 0.16173623 0.81459591]\n",
      " [0.83744107 0.96894827 0.95761525 0.34595459]\n",
      " [0.51859458 0.7020376  0.65830339 0.30966434]\n",
      " [0.47431898 0.47587342 0.42633563 0.64737868]\n",
      " [0.18855978 0.73101842 0.17748799 0.01830844]\n",
      " [0.57461643 0.56199691 0.52959569 0.62010618]\n",
      " [0.1164138  0.03327017 0.43989211 0.13606773]\n",
      " [0.56347502 0.44816385 0.21990477 0.4738117 ]\n",
      " [0.83323004 0.68605223 0.30515193 0.26877194]\n",
      " [0.39953512 0.07794265 0.7725351  0.7431957 ]\n",
      " [0.32209905 0.43036019 0.94996808 0.37996554]\n",
      " [0.9826099  0.00625044 0.31175406 0.68017961]\n",
      " [0.86859807 0.56779788 0.05958729 0.01129686]\n",
      " [0.23629942 0.03860276 0.21206404 0.97420381]\n",
      " [0.65436662 0.59246204 0.21346927 0.02936519]\n",
      " [0.58767021 0.80493701 0.64299932 0.08401979]\n",
      " [0.20009909 0.25921035 0.21471006 0.81142149]\n",
      " [0.48673528 0.04580485 0.74752609 0.86239132]\n",
      " [0.30768938 0.28841197 0.18735833 0.88196678]\n",
      " [0.64648747 0.86128828 0.07528268 0.05055726]\n",
      " [0.366826   0.21658068 0.49313995 0.11632444]\n",
      " [0.32730152 0.58531088 0.45790077 0.0756297 ]\n",
      " [0.16820898 0.68472329 0.61541948 0.68934098]\n",
      " [0.73153897 0.24768063 0.52554901 0.21893018]\n",
      " [0.5692714  0.7391856  0.82374385 0.00228887]\n",
      " [0.71247002 0.01908927 0.43170089 0.78590762]\n",
      " [0.73782227 0.85886489 0.3729381  0.13324023]\n",
      " [0.63765731 0.29597733 0.05767412 0.94394119]\n",
      " [0.07743678 0.17541352 0.52284529 0.36475478]\n",
      " [0.27142288 0.27574423 0.53289298 0.00262289]\n",
      " [0.24250604 0.42301389 0.57923691 0.73358391]\n",
      " [0.19484037 0.83006225 0.10150621 0.96672667]\n",
      " [0.72124868 0.52093118 0.34723501 0.75465265]]\n"
     ]
    }
   ],
   "source": [
    "from mountain_gridworld import MountainGridWorld\n",
    "\n",
    "env = MountainGridWorld()\n",
    "\n",
    "from models.q_learning.q_learning import learn as q_learn\n",
    "from models.q_learning.q_learning import PRECISE, NOISY\n",
    "\n",
    "model = q_learn(env, scene=\"mountain_gridworld\", max_it=100000, gamma=0.9, epsilon=0.3, alpha=0.1, obs_mode=NOISY)\n",
    "print(model.Q[::10, :])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-03T15:58:32.036687Z",
     "start_time": "2024-04-03T15:58:21.681190Z"
    }
   },
   "id": "9e67ed26051a21ab",
   "execution_count": 1
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "from state 8 action 3 to state 15 reward -1 done False confidence 0.86\n",
      "from state 15 action 3 to state 22 reward -1 done False confidence 0.5\n",
      "from state 22 action 3 to state 23 reward -1 done False confidence 0.5\n",
      "from state 23 action 3 to state 30 reward -1 done False confidence 0.77\n",
      "from state 30 action 2 to state 31 reward -1 done False confidence 0.95\n",
      "from state 31 action 2 to state 32 reward -1 done False confidence 0.77\n",
      "from state 32 action 2 to state 31 reward -1 done False confidence 0.95\n",
      "from state 31 action 2 to state 32 reward -1 done False confidence 0.77\n",
      "from state 32 action 2 to state 33 reward -1 done False confidence 0.6799999999999999\n",
      "from state 33 action 2 to state 32 reward -1 done False confidence 0.77\n",
      "from state 32 action 2 to state 31 reward -1 done False confidence 0.95\n",
      "from state 31 action 2 to state 30 reward -1 done False confidence 0.77\n",
      "from state 30 action 2 to state 29 reward -1 done False confidence 0.6799999999999999\n",
      "from state 29 action 3 to state 28 reward -1 done False confidence 0.5\n",
      "from state 28 action 3 to state 35 reward -1 done False confidence 0.59\n",
      "from state 35 action 0 to state 36 reward -1 done False confidence 0.77\n",
      "from state 36 action 3 to state 43 reward -1 done False confidence 0.6799999999999999\n",
      "from state 43 action 0 to state 44 reward -1 done False confidence 0.6799999999999999\n",
      "from state 44 action 2 to state 45 reward -1 done False confidence 0.77\n",
      "from state 45 action 2 to state 44 reward -1 done False confidence 0.6799999999999999\n",
      "from state 44 action 2 to state 43 reward -1 done False confidence 0.6799999999999999\n",
      "from state 43 action 0 to state 44 reward -1 done False confidence 0.6799999999999999\n",
      "from state 44 action 2 to state 43 reward -1 done False confidence 0.6799999999999999\n",
      "from state 43 action 0 to state 44 reward -1 done False confidence 0.6799999999999999\n",
      "from state 44 action 2 to state 43 reward -1 done False confidence 0.6799999999999999\n",
      "from state 43 action 0 to state 44 reward -1 done False confidence 0.6799999999999999\n",
      "from state 44 action 2 to state 43 reward -1 done False confidence 0.6799999999999999\n",
      "from state 43 action 0 to state 44 reward -1 done False confidence 0.6799999999999999\n",
      "from state 44 action 2 to state 43 reward -1 done False confidence 0.6799999999999999\n",
      "from state 43 action 0 to state 44 reward -1 done False confidence 0.6799999999999999\n",
      "from state 44 action 0 to state 45 reward -1 done False confidence 0.77\n",
      "from state 45 action 2 to state 44 reward -1 done False confidence 0.6799999999999999\n",
      "from state 44 action 2 to state 43 reward -1 done False confidence 0.6799999999999999\n",
      "from state 43 action 0 to state 44 reward -1 done False confidence 0.6799999999999999\n",
      "from state 44 action 2 to state 45 reward -1 done False confidence 0.77\n",
      "from state 45 action 2 to state 44 reward -1 done False confidence 0.6799999999999999\n",
      "from state 44 action 2 to state 43 reward -1 done False confidence 0.6799999999999999\n",
      "from state 43 action 0 to state 44 reward -1 done False confidence 0.6799999999999999\n",
      "from state 44 action 2 to state 43 reward -1 done False confidence 0.6799999999999999\n",
      "from state 43 action 0 to state 44 reward -1 done False confidence 0.6799999999999999\n",
      "from state 44 action 2 to state 43 reward -1 done False confidence 0.6799999999999999\n",
      "from state 43 action 2 to state 42 reward -1 done False confidence 0.86\n",
      "from state 42 action 0 to state 43 reward -1 done False confidence 0.6799999999999999\n",
      "from state 43 action 0 to state 44 reward -1 done False confidence 0.6799999999999999\n",
      "from state 44 action 2 to state 43 reward -1 done False confidence 0.6799999999999999\n",
      "from state 43 action 0 to state 42 reward -1 done False confidence 0.86\n",
      "from state 42 action 0 to state 43 reward -1 done False confidence 0.6799999999999999\n",
      "from state 43 action 0 to state 42 reward -1 done False confidence 0.86\n",
      "from state 42 action 0 to state 43 reward -1 done False confidence 0.6799999999999999\n",
      "from state 43 action 0 to state 44 reward -1 done False confidence 0.6799999999999999\n",
      "from state 44 action 2 to state 43 reward -1 done False confidence 0.6799999999999999\n",
      "from state 43 action 0 to state 44 reward -1 done False confidence 0.6799999999999999\n",
      "from state 44 action 2 to state 43 reward -1 done False confidence 0.6799999999999999\n",
      "from state 43 action 0 to state 44 reward -1 done False confidence 0.6799999999999999\n",
      "from state 44 action 2 to state 43 reward -1 done False confidence 0.6799999999999999\n",
      "from state 43 action 0 to state 36 reward -1 done False confidence 0.77\n",
      "from state 36 action 3 to state 36 reward 100 done True confidence 1\n",
      "Total reward with policy (1): 44\n",
      "[8, 15, 22, 23, 30, 31, 32, 31, 32, 33, 32, 31, 30, 29, 28, 35, 36, 43, 44, 45, 44, 43, 44, 43, 44, 43, 44, 43, 44, 43, 44, 45, 44, 43, 44, 45, 44, 43, 44, 43, 44, 43, 42, 43, 44, 43, 42, 43, 42, 43, 44, 43, 44, 43, 44, 43, 36, 36]\n"
     ]
    }
   ],
   "source": [
    "from models.q_learning.q_learning import discretize_state_and_confidence, DISCRETIZATION_RESOLUTION\n",
    "\n",
    "# test\n",
    "s = env.reset()\n",
    "obs = s\n",
    "confidence = 1\n",
    "r_sum = 0\n",
    "trajectory = [s]\n",
    "for i in range(100):\n",
    "    s_obs_and_confidence = discretize_state_and_confidence(obs, confidence)\n",
    "    a = model.get_policy(s_obs_and_confidence)\n",
    "    s1, r, done, obs, confidence = env.step(a, True)\n",
    "    r_sum += r\n",
    "    s = s1\n",
    "    trajectory.append(s)\n",
    "    if done:\n",
    "        break\n",
    "print(f\"Total reward with policy (1): {r_sum}\")\n",
    "print(trajectory)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-03T15:58:58.473240Z",
     "start_time": "2024-04-03T15:58:58.466386Z"
    }
   },
   "id": "e30830f317a7bdd2",
   "execution_count": 8
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "de430b0f0f145c5b"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
